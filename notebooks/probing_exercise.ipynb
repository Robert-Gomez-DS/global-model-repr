{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "colab_type": "code",
    "id": "WkzRe66H3iVW",
    "outputId": "b9a430a8-7eff-4475-a2a5-55138e56ccc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (2.1.1)\n",
      "Requirement already satisfied: tqdm in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (4.32.1)\n",
      "Requirement already satisfied: boto3 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (1.9.203)\n",
      "Requirement already satisfied: requests in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sentencepiece in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (0.1.82)\n",
      "Requirement already satisfied: sacremoses in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: numpy in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (1.16.4)\n",
      "Requirement already satisfied: regex in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from transformers) (2019.6.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.203 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from boto3->transformers) (1.12.203)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: click in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: docutils<0.15,>=0.10 in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.203->boto3->transformers) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/belinkov/anaconda3/envs/pytorch1.2/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.203->boto3->transformers) (2.8.0)\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/SIDN-IAP/global-model-repr\n",
    "!pip install transformers\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('global-model-repr/')\n",
    "# sys.path.append('..')\n",
    "from probing.utils import get_sentence_repr, get_model_and_tokenizer, get_pos_data\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxaHPQIG3iVf"
   },
   "source": [
    "# Get data for part-of-speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "t0-xo6-q3iVg",
    "outputId": "f2095d5f-5504-4b72-b36e-c459f7e43859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: 1254 Test sentences: 208\n",
      "Unique labels: 17\n"
     ]
    }
   ],
   "source": [
    "train_sentences, train_labels, test_sentences, test_labels, _, _, label2index = get_pos_data(\"global-model-repr/probing\", frac=0.1)\n",
    "# train_sentences, train_labels, test_sentences, test_labels, _, _, label2index = get_pos_data(\"../probing\", frac=0.1)\n",
    "num_labels = len(label2index)\n",
    "print(\"Training sentences:\", len(train_sentences), \"Test sentences:\", len(test_sentences))\n",
    "print(\"Unique labels:\", num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keg_tLaD3iVk"
   },
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXSLHwPJ3iVl"
   },
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.linear(input)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class NonlinearClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(NonlinearClassifier, self).__init__()\n",
    "        \n",
    "        self.input2hidden = torch.nn.Linear(input_dim, input_dim)\n",
    "        self.hidden2output = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden = self.input2hidden(input)\n",
    "        output = self.hidden2output(hidden)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "def build_classifier(emb_dim, num_labels, device='cpu'):\n",
    "\n",
    "    classifier = Classifier(emb_dim, num_labels).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(classifier.parameters())\n",
    "\n",
    "    return classifier, criterion, optimizer\n",
    "\n",
    "\n",
    "def build_nonlinear_classifier(emb_dim, num_labels, device='cpu'):\n",
    "\n",
    "    classifier = NonlinearClassifier(emb_dim, num_labels).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(classifier.parameters())\n",
    "\n",
    "    return classifier, criterion, optimizer\n",
    "\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "# get model and tokenizer from Transformers\n",
    "model, tokenizer, sep, emb_dim = get_model_and_tokenizer(model_name, device)\n",
    "# build classifier\n",
    "classifier, criterion, optimizer = build_classifier(emb_dim, num_labels, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kuLxynuc3iVp",
    "outputId": "9e2a7367-e2e4-41f6-d7e7-c67161b7633e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpNO3Ida3iVs",
    "outputId": "97758698-c925-45aa-a4ba-b46e5ca0c4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (linear): Linear(in_features=768, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KluH35v3iVv"
   },
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Q_On99u3iVx"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, train_representations, train_labels, \n",
    "          model, tokenizer, sep, model_name, device, \n",
    "          classifier, criterion, optimizer, batch_size=32):\n",
    "    \n",
    "    num_total = train_representations.shape[0] \n",
    "    for i in range(num_epochs):\n",
    "        total_loss = 0.\n",
    "        num_correct = 0.\n",
    "        for batch in range(0, num_total, batch_size):\n",
    "            batch_repr = train_representations[batch: batch+batch_size]\n",
    "            batch_labels = train_labels[batch: batch+batch_size]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = classifier(batch_repr)\n",
    "            pred = out.max(1)[1]\n",
    "            num_correct += pred.long().eq(batch_labels.long()).cpu().sum().item()\n",
    "            loss = criterion(out, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#         print('Training epoch: {}, loss: {}, accuracy: {}'.format(i, total_loss/num_total, num_correct/num_total))\n",
    "    return total_loss/num_total, num_correct/num_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Y8Rge5S3iV0"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gi0fG0vg3iV1"
   },
   "outputs": [],
   "source": [
    "def evaluate(test_representations, test_labels, \n",
    "             model, tokenizer, sep, model_name, device, \n",
    "             classifier, criterion, batch_size=32):\n",
    "    \n",
    "    num_correct = 0.\n",
    "    num_total = test_representations.shape[0]\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch in range(0, num_total, batch_size):\n",
    "            batch_repr = test_representations[batch: batch+batch_size]\n",
    "            batch_labels = test_labels[batch: batch+batch_size]\n",
    "            \n",
    "            out = classifier(batch_repr)\n",
    "            pred = out.max(1)[1]\n",
    "            num_correct += pred.long().eq(batch_labels.long()).cpu().sum().item()\n",
    "            total_loss += criterion(out, batch_labels)\n",
    "\n",
    "#     print('Testing loss: {}, accuracy: {}'.format(total_loss/num_total, num_correct/num_total))\n",
    "    return total_loss/num_total, num_correct/num_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate representations with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-level list: sentences, second-level lists: layers, third-level tensors of num_words x representation_dim\n",
    "train_sentence_representations = [get_sentence_repr(sentence, model, tokenizer, sep, model_name, device) \n",
    "                                  for sentence in train_sentences]\n",
    "test_sentence_representations = [get_sentence_repr(sentence, model, tokenizer, sep, model_name, device) \n",
    "                                  for sentence in test_sentences]\n",
    "\n",
    "# top-level list: layers, second-level lists: sentences\n",
    "train_sentence_representations = [list(l) for l in zip(*train_sentence_representations)]\n",
    "test_sentence_representations = [list(l) for l in zip(*test_sentence_representations)]\n",
    "\n",
    "# concatenate all word represenations\n",
    "train_representations_all = [torch.tensor(np.concatenate(train_layer_representations, 0)).to(device) for train_layer_representations in train_sentence_representations]\n",
    "test_representations_all = [torch.tensor(np.concatenate(test_layer_representations, 0)).to(device) for test_layer_representations in test_sentence_representations]\n",
    "# concatenate all labels\n",
    "train_labels = torch.tensor(np.concatenate(train_labels, 0)).to(device)\n",
    "test_labels = torch.tensor(np.concatenate(test_labels, 0)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIBpbUIv3iV4"
   },
   "source": [
    "# Experiment 1: Evaluate representation for POS quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-Hsz50R3iV5",
    "outputId": "311dd475-ee05-4d35-ffa6-92a084d8d7bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9263512762568074, Test accuracy: 0.9164086687306502\n"
     ]
    }
   ],
   "source": [
    "# Take final layer representations\n",
    "train_representations = train_representations_all[-1]\n",
    "test_representations = test_representations_all[-1]\n",
    "\n",
    "# train\n",
    "train_loss, train_accuracy = train(10, train_representations, train_labels, \n",
    "          model, tokenizer, sep, model_name, device, \n",
    "          classifier, criterion, optimizer)\n",
    "# test\n",
    "test_loss, test_accuracy = evaluate(test_representations, test_labels, \n",
    "         model, tokenizer, sep, model_name, device, \n",
    "         classifier, criterion)\n",
    "print(\"Train accuracy: {}, Test accuracy: {}\".format(train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RncHqDF3iV8"
   },
   "source": [
    "# Experiment 2: Compare representation quality across layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYqr1lX93iV9",
    "outputId": "765070f8-d1c8-47f1-a97a-9c8710f14c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0, train accuracy: 0.8647797577149632, test accuracy: 0.8465280849181778\n",
      "layer: 1, train accuracy: 0.8850072240951358, test accuracy: 0.8785935426802299\n",
      "layer: 2, train accuracy: 0.9242025710369355, test accuracy: 0.9303405572755418\n",
      "layer: 3, train accuracy: 0.9298336605786686, test accuracy: 0.9290137107474569\n",
      "layer: 4, train accuracy: 0.9328344385581447, test accuracy: 0.9294559929234851\n",
      "layer: 5, train accuracy: 0.9327973919164227, test accuracy: 0.930561698363556\n",
      "layer: 6, train accuracy: 0.931648946023043, test accuracy: 0.9303405572755418\n",
      "layer: 7, train accuracy: 0.9309080131886045, test accuracy: 0.9270234409553295\n",
      "layer: 8, train accuracy: 0.924461897528989, test accuracy: 0.9221583370190182\n",
      "layer: 9, train accuracy: 0.9146815841144, test accuracy: 0.9155241043785936\n",
      "layer: 10, train accuracy: 0.9033453117474901, test accuracy: 0.9013710747456878\n",
      "layer: 11, train accuracy: 0.8943800244507836, test accuracy: 0.8971693940734189\n",
      "layer: 12, train accuracy: 0.8649649909235728, test accuracy: 0.871517027863777\n"
     ]
    }
   ],
   "source": [
    "num_layers = len(train_representations_all)\n",
    "train_accs, test_accs = [], []\n",
    "for l in range(num_layers):\n",
    "    # build new classifier for every layer experiment\n",
    "    classifier, criterion, optimizer = build_classifier(emb_dim, num_labels, device)\n",
    "    # get layer representation \n",
    "    train_representations = train_representations_all[l]\n",
    "    test_representations = test_representations_all[l]\n",
    "    \n",
    "    # train\n",
    "    train_loss, train_accuracy = train(2, train_representations, train_labels, \n",
    "          model, tokenizer, sep, model_name, device, \n",
    "          classifier, criterion, optimizer)\n",
    "    train_accs.append(train_accuracy)\n",
    "    # test\n",
    "    test_loss, test_accuracy = evaluate(test_representations, test_labels, \n",
    "         model, tokenizer, sep, model_name, device, \n",
    "         classifier, criterion)\n",
    "    test_accs.append(test_accuracy)\n",
    "    print(\"layer: {}, train accuracy: {}, test accuracy: {}\".format(l, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sqkxu9xq3iWB"
   },
   "source": [
    "# Experiment 3: Non-linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sML_JwTh3iWC",
    "outputId": "fad24d96-bf17-4fd6-d986-89a377c5e9b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0, train accuracy: 0.8584077353387916, test accuracy: 0.8268465280849182\n",
      "layer: 1, train accuracy: 0.8772274293335309, test accuracy: 0.8361344537815126\n",
      "layer: 2, train accuracy: 0.9190160411958656, test accuracy: 0.8967271118973905\n",
      "layer: 3, train accuracy: 0.923980291186604, test accuracy: 0.8991596638655462\n",
      "layer: 4, train accuracy: 0.9252769236468714, test accuracy: 0.9033613445378151\n",
      "layer: 5, train accuracy: 0.9281665617011818, test accuracy: 0.897390535161433\n",
      "layer: 6, train accuracy: 0.9291297743859519, test accuracy: 0.8951791242812914\n",
      "layer: 7, train accuracy: 0.9256473900640907, test accuracy: 0.9040247678018576\n",
      "layer: 8, train accuracy: 0.9219427258918979, test accuracy: 0.8892083149049094\n",
      "layer: 9, train accuracy: 0.9127551587448598, test accuracy: 0.8759398496240601\n",
      "layer: 10, train accuracy: 0.9030489386137147, test accuracy: 0.8673153471915082\n",
      "layer: 11, train accuracy: 0.8948616307931686, test accuracy: 0.8591331269349846\n",
      "layer: 12, train accuracy: 0.8788574815692958, test accuracy: 0.8558160106147722\n"
     ]
    }
   ],
   "source": [
    "num_layers = len(train_representations_all)\n",
    "train_accs, test_accs = [], []\n",
    "for l in range(num_layers):\n",
    "    # build non-linear classifier\n",
    "    classifier, criterion, optimizer = build_nonlinear_classifier(emb_dim, num_labels, device)\n",
    "    # get layer representation \n",
    "    train_representations = train_representations_all[l]\n",
    "    test_representations = test_representations_all[l]\n",
    "    \n",
    "    # train\n",
    "    train_loss, train_accuracy = train(2, train_representations, train_labels, \n",
    "          model, tokenizer, sep, model_name, device, \n",
    "          classifier, criterion, optimizer)\n",
    "    train_accs.append(train_accuracy)\n",
    "    # test\n",
    "    test_loss, test_accuracy = evaluate(test_representations, test_labels, \n",
    "         model, tokenizer, sep, model_name, device, \n",
    "         classifier, criterion)\n",
    "    test_accs.append(test_accuracy)\n",
    "    print(\"layer: {}, train accuracy: {}, test accuracy: {}\".format(l, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wiAVNq0G4ei"
   },
   "source": [
    "# Experiment 4: Control labels\n",
    "\n",
    "In this experiment we test to see how much of the good performance from Experiments 2 and 3 actually come from things the POS model learned, and how much of it just comes from the probe model. To test this, we use a method from Hewitt and Liang (https://arxiv.org/pdf/1909.03368.pdf). We make a <i>control task</i> which is unrelated to the POS task and do the same probing procedure on the control task. We then measure the <i>selectivity</i> of layers; the difference between their probed accuracy on the POS task and on the control task. If a layer has learned substantial things about the POS task in particular, it should be much better at the POS task than the control task; i.e. it should have high selectivity.\n",
    "\n",
    "Following Hewitt and Liang, we use the following control task for POS tagging. Each word identity will be assigned a random POS tag, with the distribution of POS tags weighted according to their actual appearance. Each word identity will always have the same tag every time it appears. We then train and test the layers on predicting this tag from the embedding. Note that this tag is a deterministic function of the word identity, so high selectivity means the embedding actually has forgotten something about the word identity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4S30miOQ3iWF"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "vocabulary = set(\n",
    "    word\n",
    "      for sentence in (train_sentences + test_sentences)\n",
    "      for word in sentence\n",
    ")\n",
    "# all_labels = sum((x.tolist() for x in train_labels), [])\n",
    "all_labels = train_labels.tolist()\n",
    "control_map = {word: random.choice(all_labels) for word in vocabulary}\n",
    "\n",
    "control_train_labels = [torch.tensor([control_map[word] for word in sentence]) for sentence in train_sentences]\n",
    "control_test_labels = [torch.tensor([control_map[word] for word in sentence]) for sentence in test_sentences]\n",
    "control_train_labels = torch.tensor(np.concatenate(control_train_labels, 0)).to(device)\n",
    "control_test_labels = torch.tensor(np.concatenate(control_test_labels, 0)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "ZukN_X9k9_z4",
    "outputId": "881943b2-3ddf-47d5-8b02-2f3da795d066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0, test accuracy: 0.7167182662538699\n",
      "layer: 1, test accuracy: 0.7054400707651481\n",
      "layer: 2, test accuracy: 0.6824413976116762\n",
      "layer: 3, test accuracy: 0.6720477664750111\n",
      "layer: 4, test accuracy: 0.6534719150818222\n",
      "layer: 5, test accuracy: 0.6360017691287041\n",
      "layer: 6, test accuracy: 0.6043785935426802\n",
      "layer: 7, test accuracy: 0.5760725342768687\n",
      "layer: 8, test accuracy: 0.5457762052189297\n",
      "layer: 9, test accuracy: 0.5265369305616984\n",
      "layer: 10, test accuracy: 0.4955771782397169\n",
      "layer: 11, test accuracy: 0.4834144183989385\n"
     ]
    }
   ],
   "source": [
    "num_layers = len(train_representations_all)\n",
    "for l in range(num_layers):\n",
    "    classifier, criterion, optimizer = build_nonlinear_classifier(emb_dim, num_labels, device)\n",
    "    # get layer representation \n",
    "    train_representations = train_representations_all[l]\n",
    "    test_representations = test_representations_all[l]\n",
    "    \n",
    "    # train\n",
    "    train_loss, train_accuracy = train(2, train_representations, control_train_labels, \n",
    "          model, tokenizer, sep, model_name, device, \n",
    "          classifier, criterion, optimizer)\n",
    "    train_accs.append(train_accuracy)\n",
    "    # test\n",
    "    test_loss, test_accuracy = evaluate(test_representations, control_test_labels, \n",
    "         model, tokenizer, sep, model_name, device, \n",
    "         classifier, criterion)\n",
    "    test_accs.append(test_accuracy)    \n",
    "    print(\"layer: {}, test accuracy: {}\".format(l, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "probing_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
